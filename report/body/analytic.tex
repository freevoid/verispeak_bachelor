\chapter{Аналитический раздел}

В данном разделе проводится обоснование поставленной задачи, а также обзор современных подходов к решению проблемы голосовой верификации.

\section{Обоснование задачи}

Разработчики интерфейсов ищут более удобные способы взаимодействия с пользователем. Необходимость ввода пары <<имя -- пароль>> при стандартной процедуре аутентификации вынуждает пользователя помнить сложные численно-буквенные комбинации, или же возлагать это на компьютерные программы, что по своей сути небезопасно (пользователь начинает зависеть от способа хранения и степени защищенности этой конфиденциальной информации). Биометрические способы аутентификации, такие как аутентификация по голосу или по отпечаткам пальцев, позволяют не использовать пароль, что исключает не только возможность его потери, но и возможность несанкционированного входа в систему, в случае, когда злоумышленник подбирает пароль, например, простым перебором. Биометрические способы аутентификации также могут быть использованы вместе с традиционной процедурой ввода пароля, усиливая тем самым степень защиты.

На данный момент, по данным Международного Союза Электросвязи (ITU), более 26\% населения планеты имеет доступ в сеть Интернет, по данным исследовательской компании Netcraft (\url{http://news.netcraft.com/}, 2010) функционирует более 231 миллиона интернет-сайтов, веб-приложения имеют самую большую потенциальную аудиторию. Вместе с этим, в современных веб-приложениях не используются механизмы голосовой аутентификации, поэтому в качестве потенциальной целевой платформы выбрано именно пространство интернет-сайта. При этом появляются следующие ограничения:

\begin{enumerate}
\item разрабатываемый комплекс должен иметь клиент-серверную архитектуру;
\item должна обеспечиваться интеграция комплекса с остальной инфраструктурой защищаемого интернет-сайта.
\end{enumerate}

\section{Обзор существующих решений}
\label{sec:overview}

Системы голосовой аутентификации получают все большее распространение в таких сферах, как банковские услуги, при подтверждении сделок, в системах <<умный дом>>. Однако, аналогов, предоставляющих альтернативу традиционному вводу имени и пароля для входа в защищаемые разделы интернет-порталов, автором найдено не было. Далее в данном разделе дан обзор основных методов, используемых при построении современных систем голосовой аутентификации, для каждой из стадий. Раздел заканчивается краткими выводами и предположениями о направлениях исследований в данной сфере. В обзоре даны описания общих принципов и методов, не учитывая специфики данного проекта, заключающейся в особенностях веб-приложений, а также в целом приложений с клиент-серверной архитектурой.

\subsection{Постановка задачи аутентификации по голосу}

Задачи, связанные с определением пользователя по голосу, можно разделить на идентификацию и верификацию. В первом случае, задача состоит в классификации речевого сигнала, при этом каждый класс соответствует одному человеку, зарегистрированному в системе. Во втором случае, задача представляет собой бинарную классификацию. Более формально, задача верификации представляет собой проверку статистической гипотезы, которую можно сформулировать следующим образом \cite{Kinnunen04cohort}. Предположим, что неизвестный произнес высказывание $X$ и представляется пользователем $S$. Две противоположные гипотезы, в таком случае, это

\begin{equation}
\label{eq:hypothesis}
\left\{ 
    \begin{array}{lll}
        H_0 & : & \textrm{высказывание } X \textrm{ произнес } S\\
        H_1 & : & \textrm{высказывание } X \textrm{ произнес \important{не} } S,\\
    \end{array}
\right.
\end{equation}

\noindentи ядро комплекса верификации должно определить, какую из двух гипотез необходимо принять.

Работу программного комплекса верификации источника речи можно разделить на четыре логические стадии:

\begin{enumerate}
\item нормализация входного речевого сигнала;
\item выделение характерных признаков;
\item построение модели источника речи (стадия обучения);
\item принятие по построенной модели и новой входной последовательности одной из двух гипотез \refeq{eq:hypothesis}.
\end{enumerate}

Среди основных характертых особенностей в данной предметной области можно выделить следующие (по \cite{Jayanna09overview}):
\begin{itemize}
\item эффективность современных систем распознавания источника речи уменьшается, если входной сигнал зашумлен, канала передачи и прочих внешний причин. Важным моментом является попытка улучшить сигнал на этой предварительной стадии \cite{Greenwood00suv};
\item дискриминативная точность моделей теряется при появлении в речи девиантных составляющих, привносимых различными психологическими состояниями говорящего (эмоции, напряжение). Существуют решения, позволяющие компенсировать данные составляющие \cite{Alamo96discriminative};
\item для биометрической аутентификации человека современным системам требуется значительное количество речевых данных (порядка десятков минут на человека). В таких уславиях возрастает и требовательность системы к вычислительным ресурсам. Применимость технологий верификации по голосу увеличится, если удастся разработать технологии, позволяющие получить удовлетворительную производительность с использованием относительно малого количества данных (10-15 секунд). Существующим решением является использование модели гауссовой смеси с использованием так называемой универсальной фоновой модели (UBM -- \important{Universal Background Model}) \cite{Reynolds00speakerverification}.
\end{itemize}

\subsection{Нормализация входного речевого сигнала}

Важной стадией голосовой аутентификации является предварительная подготовка речевого сигнала до выделения характерных признаков. Основные применяемые в данной области методы нормализации:

\begin{itemize}
\item удаление из записи фрагментов, не содержащих речь (<<тишины>>). Самым простым и прямолинейным способом является определение уровня <<энергии сигнала>> и удаление тех кадров, в которых мощность не превышает заданный уровень, соответствующий внешнему шуму. Другой широко распространенный метод основан на подсчете количества изменений знака амплитуды внутри кадра (\important{zero-crossing rate}). Предложены также комбинации данных методов \cite{Greenwood00suv}, \cite{Bachu04zcr};
\item подавление шума, вызванного окружением. В данном случае используются методы нормализации, такие как нормализация по средним (\important{mean normalization}). Метод заключается в нахождении среднего значения энергии кадра сигнала и вычитании его из всех сэмплов (чаще данный метод используется после выделения характерных признаков);
\item частотная развертка. В данном случае, изпользуя частотный спектр сигнала, фильтруются частоты, находящиеся вне заданного диапазона, обычно $[300\textrm{Гц}, 8000\textrm{Гц}]$, соответствующего спектру речи человека.
\end{itemize}

В данной работе применены все три метода нормализации, так как они независимы друг от друга и, применяемые совместно, позволяют получить точность выше, чем по отдельности \cite{Jayanna09overview}.

\subsection{Выделение характерных признаков}
\label{sec:analytic:features}

После нормализации сигнала, необходимо выделить признаки, которые характеризуют особенности вокального тракта человека. В сфере обработки сигналов и, в частности, распознавания речи и верификации по голосу, наиболее активное применение нашли так называемые мел-частотные коэффициенты кепстра (\important{MFCC}), отражающие психофизическое восприятие звука человеком. Существуют также исследования, в которых предлагается использование \important{LPCC (Linear prediction coding coefficients)}, вейвлет-преобразований \cite{Medvedev06wavelets}, а также различных их комбинаций. Однако, отдельные исследования показали \cite{Tierney80LPC}, что LPC коэффициенты деградируют, если сигнал зашумлен. В данной работе использованы характерные признаки, основанные на MFCC, как наиболее изученные и подтвердившие свою эффективность в ряде исследований \cite{Jayanna09overview}.

Речевой сигнал изначально представляет собой массив значений амплитуд, полученный с помощью дискретизации исходного аналогового сигнала с некоторой частотой сэмплирования $f_s$. На рисунке~\ref{fig:waveform} представлен пример такого входного сигнала.

\begin{figure}[h!]
\center{\includegraphics[width=0.7\textwidth]{include/waveform_eps.pdf}}
\caption{Пример речевого сигнала (запись слова <<Николай>>)}
\label{fig:waveform}
\end{figure}

Для получения мел-частотных коэффициентов кепстра из входного сигнала, необходимо произвести следующие действия:

\begin{enumerate}
\item исходный сигнал разбивается на кадры фиксированного размера (10-30мс) с использованием окон Хэмминга;
\item для каждого кадра выполняется дискретное преобразование Фурье;
\item полученные коэффициенты возводятся в квадрат и отображаются в мел-пространство с помощью перекрывающихся треугольных окон (\important{mel-scale filterbank});
\item для полученного массива выполняется дискретное преобразование косинусов (\important{Discrete Cosine Transform}), массив в данном случае рассматривается как сигнал;
\item коэффициенты преобразования и являются мел-частотными коэффициентами кепстра.
\end{enumerate}

В итоге для каждого кадра из исходного речевого сигнала получаем $N$ коэффициентов $\vec M = (M_1, M_2, \ldots, M_N)$. Первый коэффициент $M_1$ исключается из вектора признаков, так как в действительности представляет собой <<энергию>> сигнала \cite{Reynolds95gmm}. В дополнение к ним, для уменьшения влияния канала передачи сигнала, в современных системах используют \cite{Reynolds95gmm} разницу коэффициентов, находящихся на расстоянии $W$ кадров от текущего ($t$):

\begin{equation}
\label{eq:deltamfcc}
\Delta \vec M = \vec M_{t+W} - \vec M_{t-W}.
\end{equation}

Последние также называют \important{динамическими} характеристиками сигнала, тогда как мел-частотные коэффициенты являются \important{статическими}.

\subsection{Построение модели источника речи}

Целью данного этапа является построение модели источника речи по специфичным для него векторам характеристических признаков.

В ранних исследованиях в области определения источника речи использовалось прямое сопоставление шаблонов. В сопоставлении шаблонов тестируемый вектор и вектор-образец (обучающий вектор) сравниваются напрямую с помощью некоторой меры похожести, вычисление которой является ключевым при данном подходе. Изначально были использованы Евклидово расстояние или расстояние Махаланобиса. В конце 70-х японские ученые предложили \cite{Sakoe78DTW} концепцию динамической деформации времени (\important{Dynamic Time Warping, DTW}), изначально для распознавания слов. В последствии, Фуруи \cite{Furui81cepstral} предложил использовать данный алгоритм для тексто-зависимой идентификации источника речи. Основным недостатком данного метода считается его высокая требовательность к вычислительным ресурсам по мере увеличения числа характеристических векторов. Однако, в последнее время предложены методы \cite{Lemire09dtw}, позволяющие с помощью эффективного вычисления нижних границ меры уменьшить вычислительную нагрузку алгоритма \important{DTW}.

Следующий шаг в исследовании данной области был сделан в направлении алгоритмов кластеризации. Алгоритм K-средних был использован для получения специфичных для источника речи кодовых векторов для векторного квантования \cite{Soong85VQ}. Был также предложен подход на основе теории нечетких множеств (нечеткое векторное квантование с использованием алгоритма C-средних) \cite{Bezdek78FVQ}, показавший лучшие результаты, по сравнению со стандартным алгоритмом K-средних.

Аппарат скрытых Марковских моделей (\important{Hidden Markov Models, HMM}), успешно применяемый для распознавания речи, был также использован для задачи голосовой идентификации/верификации \cite{Olsson02hmmann}, \cite{Falavigna_comparisonof}. Основным предположением является то, что текущее состояние модели зависит только от предыдущего. В контексте скрытых Марковских моделей, решение задачи верификации требует построения моделей фонем, составляющих речевой сигнал.

В 1995 Рейнольдс предложил модели смесей Гауссиан для решения задачи идентификации/верификации по голосу \cite{Reynolds95gmm}. Это наиболее широко распространенный подход, основанный на аппарате математической статистики. Цель данного метода -- моделирование функции плотности распределения векторов характерных признаков, в общем случае нелинейной. В данном методе, сложное распределение моделируется с помощью взвешенной суммы плотностей многомерных нормальных распределений (компонент смеси).

В качестве примера, на рисунке~\ref{fig:gmm_hist} показана гистограмма (выборочная плотность) распределения отдельно взятого кепстрального коэффициента для записи речи диктора. Речь была записана в профессиональной студии, длительность записи после удаления тишины -- 126 секунд. На рисунке~\ref{fig:gmm_pdf} показана плотность распределения полученной по данным записи модели.

\begin{figure}[t!]
\center{\includegraphics[height=0.35\textheight]{include/gmm_hist_svg.pdf}}
\caption{Пример выборочной плотности распределения кепстрального коэффициента}
\label{fig:gmm_hist}
\end{figure}
\begin{figure}[h!]
\center{\includegraphics[height=0.35\textheight]{include/gmm_pdf_svg.pdf}}
\caption{Аппроксимация функции плотности распределения кепстрального коэффициента с помощью смеси Гауссиан}
\label{fig:gmm_pdf}
\end{figure}

Размерность каждого из распределений $D$ совпадает с размерностью вектора характерных признаков. Более формально, плотность распределения описывается следующим выражением:

\begin{equation}
p(\vec x | \lambda) = \sum_{i=1}^K{\omega_i p_i(\vec x)},
\end{equation}

\noindent где $K$ -- количество компонент,\\
$\vec x$ -- вектор характерных признаков,\\
$\omega_i$ -- вес $i$-ой компоненты, веса удовлетворяют условию $\sum_{i=1}^K w_i = 1$,\\
$p_i$ -- плотность распределения $i$-ой компоненты.

Плотность распределения каждой компоненты -- это $D$-мерный Гауссиан \cite{BMSTUM16}:

\begin{equation}
\label{eq:mdnormalpdf}
p_i(\vec x) = \frac{1}{(2\pi)^{D/2} |\Sigma_i|^{1/2}}e^{-1/2(\vec x - \vec \mu_i)^T \Sigma_i^{-1} (\vec x - \vec \mu_i)},
\end{equation}

\noindent где $\vec \mu_i$ -- вектор математического ожидания,\\
$\Sigma_i$ -- матрица ковариаций.

Плотность распределения смеси Гауссиан полностью описывается параметрами компонент и значениями весов. Параметры модели представим в следующей нотации:

\begin{equation}
\lambda = \{ \omega_i, \vec \mu_i, \Sigma_i  \}, i = \overline{1,K}.
\end{equation}

Каждый пользователь представлен собственной моделью $\lambda$.

Модель смеси Гауссиан может иметь различные типы, в зависимости от вида матриц ковариаций $\Sigma_i$. В одном случае может использоваться диагональная матрица (все элементы, кроме диагональных, всегда равны нулю, диагональные элементы в данном случае являются значениями средне-квадратичных отклонений $\sigma^2$). В другом случае используются полные матрицы ковариаций. Также возможно использование общей, глобальной матрицы для всех компонент. Эксперименты, проведенные в рамках основополагающей работы по данной теме \cite{Reynolds95gmm}, показали, что лучший результат может быть получен с использованием диагональных матриц ковариаций, отдельных для каждой из компонент. Основным аргументом против использования диагональных матриц является тот факт, что диагональные матрицы подразумевают статистическую независимость коэффициентов вектора характерных признаков. Однако, как показали эксперименты Рейнольдса, смоделировать эту зависимость можно путем введения дополнительных компонент в смесь. Так как вычисления в случае диагональных матриц значительно упрощаются (нет необходимости инвертировать матрицу ковариаций при вычислении \refeq{eq:mdnormalpdf}), автор предлагает использование именно этого варианта.

Для определения параметров модели $\lambda$ существуют несколько методов, наиболее распространенным из которых является метод максимального правдоподобия \cite{BMSTUM17}. Задача метода состоит в нахождении по заданным обучающим данным таких параметров модели, при которых функция правдоподобия модели достигает максимума. Для последовательности из $T$ обучающих векторов $X = \{ \vec x_1, \vec x_2, \ldots \vec x_T \}$, функция правдоподобия может быть записана как

\begin{equation}
\label{eq:likelihood}
p(X | \lambda) = \prod_{t=1}^T p(\vec x_t | \lambda).
\end{equation}

\label{sec:analytic:em}
Прямая максимизация выражения \refeq{eq:likelihood} невозможна, так как функция от параметров $\lambda$ нелинейна. Однако, приближенные значения могут быть получены с помощью алгоритма EM (\important{Expectation-Maximization}) \cite{Dempster77EM}.

После этапа обучения, мы имеем готовую модель $\lambda$, соответствующую данной персоне. Теперь, по данной тестовой последовательности, мы можем вычислить функцию правдоподобия $p(S|H_0)$ из выражения \refeq{eq:hypothesis}.

Основным вопросом остается вычисление второй функции, $p(S|H_1)$. По определению, она равна вероятности того, что тестовая последовательность произнесена \important{кем-то, кроме $S$}. В научном сообществе существуют два основных подхода к моделированию альтернативной гипотезы: универсальная фоновая модель (<<мировая>> модель) и когортные модели.

\label{sec:analytic:ubm}
Универсальная фоновая модель (\important{Universal Background Model, UBM}) -- это модель, цель которой характеризовать всех возможных источников речи <<мира>> во всех возможных контекстах. Данная модель обучается на большом количестве (несколько часов) речевых данных от множества источников речи, сбалансированного по гендерному типу, а также, по возможности, по оборудованию и стандартным условиям. Вычисление правдоподобия $H_1$ в таком случае осуществляется аналогично $H_0$:

\begin{equation}
\label{eq:likelihood_ubm}
p(S|H_1) = p(X|\lambda_{UBM}),
\end{equation}

\noindent где $\lambda_{UBM}$ -- универсальная фоновая модель.

Когортные модели (\important{Cohort speaker models}) -- это способ оценки правдоподобия гипотезы $H_1$, при котором вместе моделирования всего мира, из имеющихся моделей выделяется небольшое подмножество, называемое <<когортным множеством>>, $\mathbb{C}_S$. Возникают следующие задачи:
\begin{itemize}
\item необходимо выбрать способ выделения когортного множества $\mathbb{C}_S$. Существуют два противоположных по смыслу подхода: определять по мере правдоподобия наиболее близкие к целевой модели на стадии обучения; выбирать наиболее близких по мере правдоподобия к тестируемому образцу (на стадии верификации). В \cite{Kinnunen04cohort} показано, что второй способ позволяет добиться меньшего показателя ошибки;
\item необходимо выбрать способ получения меры правдоподобия гипотеза $H_1$ на основе мер моделей из когортного множества. Широко распространены два метода: взятие максимума из значений и взятие среднего арифметического.
\end{itemize}

Очевидным недостатком данного подхода является его вычислительная нагрузка по сравнению с UBM. Вместо того, чтобы вычислять $p(S|H_1)$ по выражению~\refeq{eq:likelihood}, необходимо выбирать $N_{\mathbb{C}_S} = |\mathbb{C}_S|$ когортных моделей из базы, что приводит к вычислению аналогичного выражения для \important{всех} моделей, отличных от целевой. В \cite{Kinnunen04cohort} предложен метод предварительного квантования моделей, при котором значительно уменьшается круг поиска когортных моделей.

Подход на основе смеси Гауссиан показывает результат для задачи идентификации на уровне 94.5\% лишь в случае большого количества данных на стадии обучения (60-90 секунд для источника речи) \cite{Reynolds95gmm}. Поэтому были предложены различные методы адаптации, основным из которых можно выделить Байесово обучение \cite{Reynolds00speakerverification}. В данном методе модель источника речи получают путем адаптации параметров <<мировой>> модели по обучающим векторам данного человека.

В данной работе используется подход на основе смеси Гауссиан как наиболее развитый и теоретически обоснованный метод получения модели источника речи для голосовой верификации.

\subsection{Принятие решения}
\label{sec:analytic:decision}

Предположим, что меры правдоподобия обеих гипотез \refeq{eq:hypothesis} известны. Рассмотрим \important{отношение правдоподобия}:

\begin{equation}
\label{eq:lr}
LR_{H_0, H_1} = \frac{p(S|H_0)}{p(S|H_1)},
\end{equation}

\noindent в таком случае, отношение правдоподобия дает оптимальное решение в Байесовом смысле (классификация с минимизацией рисков) \cite{Fukunaga90Intro}. Тогда, процедура принятия решения выглядит следующим образом:

\begin{equation}
\label{eq:decision}
\textrm{Решение } = \left\{ 
    \begin{array}{ll}
        H_0, & LR_{H_0, H_1} > \Theta_{S} \\
        H_1, & LR_{H_0, H_1} \leq \Theta_{S} \\
    \end{array}
\right.
\end{equation}

Ключевым моментом в \refeq{eq:decision} является выбор числа $\Theta_{S}$ (величины порога для пользователя $S$). Величина порога $\Theta_i$ определяется из образцов для обучения таким образом, чтобы обеспечивался необходимый уровень ошибок 1-ого и 2-ого рода. Порог также может быть глобальным для всех пользователей. При использовании отдельного порога для каждого из источников речи возникает проблема нахождения величины этого порога, так как это величина, определяемая экспериментально. Для этого необходимо иметь дополнительные записи фраз для тестирования полученной модели и определения ее чувствительности по отношению к данному источнику речи. Данное требование осложняет процесс регистрации в системе, поэтому следует предусмотреть как персональный, так и глобальный порог вхождения.

\section{Выводы}
\label{sec:analytic:conclusion}

В результате проведенного исследования предметной области, можно сформировать следующие выводы:

\begin{itemize}
\item системы голосовой аутентификации в данный момент не имеют широкого применения в веб-среде;
\item на процесс голосовой аутентификации влияют внешние шумы, поэтому необходимо предусмотреть методы нормализации (описанные в разделе~\ref{sec:analytic:normalization});
\item подход на основе использования смеси Гауссиан является наиболее изученным и теоретически обоснованным, поэтому он должен быть использован при разработке программного комплекса;
\item в связи со спецификой метода (тексто-независимостью), необходимо разработать алгоритм фильтрации входной последовательности для удаления сегментов, не содержащих речи (удаление тишины);
\item необходимо получить параметры для модели, которая будет использована как универсальная фоновая модель (см. раздел~\ref{sec:analytic:ubm});
\item необходимо определить экспериментально величину порога вхождения для использования в разрабатываемом программном комплексе;
\end{itemize}

